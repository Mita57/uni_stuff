title;keywords;annotation;class
Formulating LLE using alignment technique;"lle; ltsa; nonlinear dimensionality reduction; manifold learning;";LLE is a well-known method to nonlinear dimensionality reduction. In this short paper, we present an alternative way to formulate LLE. The alignment technique is exploited to align the local coordinates on the local patches of manifolds to be the global ones. The efficient computation of embedding coordinates of LLE automatically appears in the proposed framework.;2
Sequence-driven features for prediction of subcellular localization of proteins;"protein sequence feature extraction; subcellular localization prediction; support vector machine;";Prediction of the cellular location of a protein plays an important role in inferring the function of the protein. Feature extraction is a critical part in prediction systems, requiring raw sequence data to be transformed into appropriate numerical feature vectors while minimizing information loss. In this paper, we present a method for extracting useful features from protein sequence data. The method employs local and global pairwise sequence alignment scores as well as composition-based features. Five different features are used for training support vector machines (SVMs) separately and a weighted majority voting makes a final decision. The overall prediction accuracy evaluated by the 5-fold cross-validation reached 88.53% for the eukaryotic animal data set. Comparing the prediction accuracy of various feature extraction methods, provides a biological insight into the location of targeting information. Our experimental results confirm that our feature extraction methods are very useful for predicting subcellular localization of proteins.;2
Signatures versus histograms: Definitions, distances and algorithms;"distance between histograms; signature; earth mover distance; second-order random graphs;";The aim of this paper is to present a new method to compare histograms. The main advantage is that there is an important time-complexity reduction with respect to the methods presented before. This reduction is statistically and analytically demonstrated in the paper.;3
Multisets mixture learning-based ellipse detection;"ellipse detection; multisets mixture learning; hough transform;";We develop an ellipse detection algorithm based on the multisets mixture learning (MML) that differs from the conventional Hough transform perspective. The algorithm developed has potential advantages in terms of noise resistance, incomplete ellipse detection, and detecting a multitude of ellipses.;4
FuzzyBagging: A novel ensemble of classifiers;"classifier design and evaluation; machine learning;";In this work, a new method for the creation of classifier ensembles is introduced. The patterns are partitioned into clusters to group together similar patterns, a training set is built using the patterns that belong to a cluster. Each of the new sets is used to train a classifier. We show that the approach here presented, called FuzzyBagging, obtains performance better than Bagging.;1
Preserving boundaries for image texture segmentation using grey level co-occurring probabilities;"co-occurrence probabilities; co-occurrence matrix; digital imaging; computer vision; segmentation; synthetic aperture radar; sea ice; texture; remote sensing;";Texture analysis has been used extensively in the computer-assisted interpretation of digital imagery. A popular texture feature extraction approach is the grey level co-occurrence probability (GLCP) method. Most investigations consider the use of the GLCP texture features for classification purposes only, and do not address segmentation performance. Specifically, for segmentation, the pixels in an image located near texture boundaries have a tendency to be misclassified. Boundary preservation when using the GLCP texture features for image segmentation is important. An advancement which exploits spatial relationships has been implemented. The generated features are referred to as weighted GLCP (WGLCP) texture features. In addition, an investigation for selecting suitable GLCP parameters for improved boundary preservation is presented. From the tests, WGLCP features provide improved boundary preservation and segmentation accuracy at a computational cost. As well, the GLCP correlation statistical parameter should not be used when segmenting images with high contrast texture boundaries.;1
A clustering method for automatic biometric template selection;"biometrics; template selection; faces; signatures; clustering; prototype;";The problem addressed in this paper is the template selection and update in biometrics based on clustering. Template selection is a reliable method to reduce the number of templates used in a biometric system to account for variations observed in a persons biometric data. An efficient method based on clustering with automatic selection of the number of clusters is proposed in this work for finding subgroups of similar templates which are used for prototype selection.;1
A comparative study of combining multiple enrolled samples for fingerprint verification;"fingerprint verification; decision fusion; feature fusion; multiple enrolled impressions;";"In fingerprint verification systems, there are usually multiple (from two to four) enrolled impressions for a same finger. The performance of the systems can be improved by combining these impressions through feature fusion or decision fusion strategy. In this paper, different schemes to combine multiple enrolled impressions are comparatively studied. Experimental results show that a larger improvement can be obtained by using decision fusion scheme than feature fusion. In all decision fusion rules, sum rule outperforms voting rule a little whether using similarity or Neyman&ndash;Pearson rule. Based on the observation that the performance of these two strategies can complement each other, we also propose a novel fusion scheme to further combine feature fusion and decision fusion, which can produce an even better result.";3
Fingerprint matching using ridges;"fingerprint; minutiae; ridge matching; curve matching; alignment; dynamic programming;";Traditionally, fingerprint matching is minutia-based, which establishes the minutiae correspondences between two fingerprints. In this paper, a novel fingerprint matching algorithm is presented, which establishes both the ridge correspondences and the minutia correspondences between two fingerprints. First N initial substructure (including a minutia and adjacent ridges) pairs are found by a novel alignment method. Based on each of these substructure pairs, ridge matching is performed by incrementally matching ridges and minutiae, and then a matching score is computed. The maximum one of the N scores is used as the final matching score of two fingerprints. Preliminary results on FVC2002 databases show that ridge matching approach performs comparably with the minutia-based one.;3
Dynamic registration selection for fingerprint verification;"biometrics; fingerprint verification; registration; classifier combination; bayesian classifier; fingerprint alignment; fingerprint verification competition;";"Information fusion is a powerful approach to increasing the accuracy of biometric authentication systems, and is currently an active area of research. The majority of studies focus on combining the results from multiple verification systems at the match score level using either a classification or combination scheme. However, there are advantages to performing the fusion at an earlier stage of processing. Fingerprint registration involves finding the translation and rotation parameters that align two fingerprints; a challenging problem that can be approached in a number of ways. The fusion of fingerprint alignment algorithms is introduced in the form of dynamic registration selection. A Bayesian statistical framework is used to select the most probable alignment produced by competing algorithms. The results of the proposed technique are tested on multiple FVC 2002 databases, and are shown to outperform methods based on match score combination.";3
A systematic method for fingerprint ridge orientation estimation and image segmentation;"ridge orientation; neural network; fingerprint segmentation; remaining ridges; secondary segmentation; segmentation revision; minutiae detection;";This paper proposes a scheme for systematically estimating fingerprint ridge orientation and segmenting fingerprint image by means of evaluating the correctness of the ridge orientation based on neural network. The neural network is used to learn the correctness of the estimated orientation by gradient-based method. The trained network is able to distinguish correct and incorrect ridge orientations, and as a consequence, the falsely estimated ridge orientation of a local image block can be corrected using the around blocks of which orientations are correctly estimated. A coarse segmentation can also be done based on the trained neural network by taking the blocks of correctly estimated orientation as foreground and the blocks of incorrectly estimated orientation as background. Besides, following the steps of estimating ridge orientation correctness, a secondary segmentation method is proposed to segment the remaining ridges which are the afterimage of the previously scanned fingers. The proposed scheme serves for minutiae detection and is compared with VeriFinger 4.2 published by Neurotechnologija Ltd. in 2004, and the comparison shows that the proposed scheme leads to an improved accuracy of minutiae detection.;3
Supervised range-constrained thresholding;"biomedical mri; brain; computer vision; computerised tomography; image segmentation; medical image processing; brain magnetic resonance images; cameraman image; character recognition; classification error; computer vision; computerised tomography chest images; fingerprint identification; histogram; intensity frequency range; medical image segmentation; nonsupervised thresholding methods; region of interest; supervised range-constrained thresholding; supervised thresholding approach; biomedical imaging; computed tomography; computer vision; entropy; frequency estimation; histograms; image processing; image segmentation; noise robustness; radiography; histogram; region of interest (roi); robust thresholding; supervision; thresholding; algorithms; artificial intelligence; image enhancement; image interpretation, computer-assisted; imaging, three-dimensional; information storage and retrieval; pattern recognition, automated; reproducibility of results; sensitivity and specificity;""";A novel thresholding approach to confine the intensity frequency range of the object based on supervision is introduced. It consists of three steps. First, the region of interest (ROI) is determined in the image. Then, from the histogram of the ROI, the frequency range in which the proportion of the background to the ROI varies is estimated through supervision. Finally, the threshold is determined by minimizing the classification error within the constrained variable background range. The performance of the approach has been validated against 54 brain MR images, including images with severe intensity inhomogeneity and/or noise, CT chest images, and the Cameraman image. Compared with nonsupervised thresholding methods, the proposed approach is substantially more robust and more reliable. It is also computationally efficient and can be applied to a wide class of computer vision problems, such as character recognition, fingerprint identification, and segmentation of a wide variety of medical images.;4
Singular point detection by shape analysis of directional fields in fingerprints;"singular point; fingerprint; reference point; directional field; classification; alignment;";This paper presents a new fingerprint singular point detection method that is type-distinguishable and applicable to various fingerprint images regardless of their resolutions. The proposed method detects singular points by analyzing the shapes of the local directional fields of a fingerprint image. Using the predefined rules, all types of singular points (upper core, lower core, and delta points) can be extracted accurately and delineated in terms of the type of singular points. In case of arch-type fingerprints there exists no singular point, but reference points for arch-type fingerprints are required to be detected for registration. Therefore, we propose a new reference point detection method for arch-type fingerprints as well. The result of the experiments on the two public databases (FVC2000 2a, FVC2002 2a) with different resolutions demonstrates that the proposed method has high accuracy in locating each types of singular points and detecting the reference points of arch-type fingerprints without regard to their image resolutions.;4
Fingerprint matching by genetic algorithms;"fitness value; corresponding triangles; minutiae; optimization; fingerprint verification;";Fingerprint matching is still a challenging problem for reliable person authentication because of the complex distortions involved in two impressions of the same finger. In this paper, we propose a fingerprint-matching approach based on genetic algorithms (GA), which tries to find the optimal transformation between two different fingerprints. In order to deal with low-quality fingerprint images, which introduce significant occlusion and clutter of minutiae features, we design a fitness function based on the local properties of each triplet of minutiae. The experimental results on National Institute of Standards and Technology fingerprint database, NIST-4, not only show that the proposed approach can achieve good performance even when a large portion of fingerprints in the database are of poor quality, but also show that the proposed approach is better than another approach, which is based on mean-squared error estimation.;3
A novel image-hiding scheme based on block difference;"image hiding; block difference;";To transmit a secret-image securely by embedding it into a cover-image without drawing the unintended observers attention, a novel image-hiding scheme is proposed. By exploring the block correlation between the cover-image and the secret-image, the stego-image quality can be greatly improved. Experimental results demonstrate that the stego-image has a high peak signal-to-noise ratio and the stego-image is almost the same as the cover-image.;4
Adaptive degraded document image binarization;"degraded document images; local adaptive binarization;";This paper presents a new adaptive approach for the binarization and enhancement of degraded documents. The proposed method does not require any parameter tuning by the user and can deal with degradations which occur due to shadows, non-uniform illumination, low contrast, large signal-dependent noise, smear and strain. We follow several distinct steps: a pre-processing procedure using a low-pass Wiener filter, a rough estimation of foreground regions, a background surface calculation by interpolating neighboring background intensities, a thresholding by combining the calculated background surface with the original image while incorporating image up-sampling and finally a post-processing step in order to improve the quality of text regions and preserve stroke connectivity. After extensive experiments, our method demonstrated superior performance against four (4) well-known techniques on numerous degraded document images.;4
Converting non-parametric distance-based classification to anytime algorithms;"anytime classification; nearest neighbor applications;";For many real world problems we must perform classification under widely varying amounts of computational resources. For example, if asked to classify an instance taken from a bursty stream, we may have anywhere from several milliseconds to several minutes to return a class prediction. For such problems an anytime algorithm may be especially useful. In this work we show how we convert the ubiquitous nearest neighbor classifier into an anytime algorithm that can produce an instant classification, or if given the luxury of additional time, can continue computations to increase classification accuracy. We demonstrate the utility of our approach with a comprehensive set of experiments on data from diverse domains. We further show the utility of our work with two deployed applications, in classifying and counting fish, and in classifying insects.;1
